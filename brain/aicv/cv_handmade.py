# -*- coding: utf-8 -*-
"""CV_handmade.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17c-SniisNjFlQtO8WBlSrQ0hct7ytR-L
"""

from google.colab import drive
drive.mount('/content/drive')

IMG_DIR = "/content/drive/MyDrive/data/chess_photo"
img_paths = sorted(glob.glob(os.path.join(IMG_DIR, "*")))
print("num images:", len(img_paths))
print("first:", img_paths[0] if img_paths else "None")

import os

IMG_DIR = "/content/drive/MyDrive/data/chess_photo"

files = sorted(os.listdir(IMG_DIR))

for i, filename in enumerate(files, start=1):
    old_path = os.path.join(IMG_DIR, filename)

    # 파일만 처리 (폴더 제외)
    if not os.path.isfile(old_path):
        continue

    ext = os.path.splitext(filename)[1]  # .jpg / .png 유지
    new_name = f"frame{i:02d}{ext}"       # frame01, frame02, ...
    new_path = os.path.join(IMG_DIR, new_name)

    os.rename(old_path, new_path)

print("Rename complete!")

import os, glob
import cv2

IMG_DIR = "/content/drive/MyDrive/data/chess_photo"   # 원본 프레임 폴더
OUT_DIR = "/content/drive/MyDrive/data/chess_cells_v2"  # 저장 폴더
os.makedirs(OUT_DIR, exist_ok=True)

img_paths = sorted(glob.glob(os.path.join(IMG_DIR, "*")))
print("num images:", len(img_paths))
print("first:", img_paths[0] if img_paths else "None")

def split_into_cells_new_coords(img_bgr, out_dir, frame_id):
    H, W = img_bgr.shape[:2]
    cell_h = H // 8
    cell_w = W // 8

    for r in range(8):      # 0=위 ... 7=아래
        for c in range(8):  # 0=왼 ... 7=오른
            y0, y1 = r * cell_h, (r + 1) * cell_h
            x0, x1 = c * cell_w, (c + 1) * cell_w

            cell = img_bgr[y0:y1, x0:x1]

            file_char = chr(ord('a') + r)   # 위가 a, 아래가 h
            rank_char = str(1 + c)          # 왼이 1, 오른이 8
            sq = file_char + rank_char      # 예: a1, a8, h1, h8

            fn = f"frame{frame_id:02d}_{sq}.png"
            cv2.imwrite(os.path.join(out_dir, fn), cell)

# 실행
for i, p in enumerate(img_paths, start=1):  # frame01부터 맞추고 싶으면 start=1
    img = cv2.imread(p)
    if img is None:
        continue
    img = cv2.resize(img, (640, 480), interpolation=cv2.INTER_AREA)

    split_into_cells_new_coords(img, OUT_DIR, i)

print("saved to:", OUT_DIR)

import os, csv

LABEL_DIR = "/content/drive/MyDrive/data/chess_labels_csv"
os.makedirs(LABEL_DIR, exist_ok=True)

# a1이 왼쪽 위, h8이 오른쪽 아래
files = list("abcdefgh")
ranks = list(range(1,9))

def make_blank_csv(frame_name):
    path = os.path.join(LABEL_DIR, f"{frame_name}.csv")
    with open(path, "w", newline="") as f:
        w = csv.writer(f)
        w.writerow([""] + [str(r) for r in ranks])  # header
        for i, filech in enumerate(files):
            w.writerow([filech] + ["0"]*8)          # 기본 0으로 채움
    return path

# 예: frame01~frame50 템플릿 만들기
for i in range(1, 51):
    make_blank_csv(f"frame{i:02d}")

print("CSV templates created at:", LABEL_DIR)

#=============

import os, glob, re
import numpy as np
import pandas as pd
import cv2

IMG_DIR   = "/content/drive/MyDrive/data/chess_photo"
LABEL_DIR = "/content/drive/MyDrive/data/chess_labels_csv"  # 네가 1~20 넣어둔 곳

# 예측 결과를 저장할 폴더 (원하면 LABEL_DIR 그대로 써도 됨)
PRED_DIR  = "/content/drive/MyDrive/data/chess_labels_pred_csv"
os.makedirs(PRED_DIR, exist_ok=True)

def find_frame_image(frame_idx):
    # frame01, frame02 ... 에 맞는 파일을 IMG_DIR에서 찾아줌 (확장자 자유)
    key = f"frame{frame_idx:02d}"
    cand = sorted(glob.glob(os.path.join(IMG_DIR, key + ".*")))
    if len(cand) == 0:
        raise FileNotFoundError(f"No image found for {key} in {IMG_DIR}")
    return cand[0]

FILES = list("abcdefgh")
RANKS = [str(i) for i in range(1,9)]

def load_label_csv(frame_idx):
    path = os.path.join(LABEL_DIR, f"frame{frame_idx:02d}.csv")
    df = pd.read_csv(path)
    # df 첫 열: file(a~h), 나머지 열: 1~8
    arr = df.iloc[:, 1:].astype(int).values  # (8,8)
    assert arr.shape == (8,8)
    return arr

def save_label_csv(arr_8x8, out_path):
    # arr_8x8 row: a..h, col: 1..8 (왼쪽 위=a1)
    df = pd.DataFrame(arr_8x8, columns=RANKS)
    df.insert(0, "", FILES)   # 첫 열에 a~h
    df.to_csv(out_path, index=False)

def split_cells(img_bgr):
    # 반환: cells (64, 3, 64, 64) 같은 텐서 입력 전 단계로 numpy list
    img = cv2.resize(img_bgr, (640, 480), interpolation=cv2.INTER_AREA)
    H, W = img.shape[:2]
    ch, cw = H // 8, W // 8

    cells = []
    meta  = []  # (r,c) 저장
    for r in range(8):       # 0=위(a) ... 7=아래(h)
        for c in range(8):   # 0=왼(1) ... 7=오른(8)
            y0, y1 = r*ch, (r+1)*ch
            x0, x1 = c*cw, (c+1)*cw
            cell = img[y0:y1, x0:x1]   # BGR
            cell = cv2.resize(cell, (64,64), interpolation=cv2.INTER_AREA)
            cells.append(cell)
            meta.append((r,c))
    return cells, meta

!pip -q install torch torchvision

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as T

device = "cuda" if torch.cuda.is_available() else "cpu"
print("device:", device)

class ChessCellDataset(Dataset):
    def __init__(self, frame_indices, train=True):
        self.samples = []  # (img_path, r, c, label)
        self.train = train

        for fi in frame_indices:
            img_path = find_frame_image(fi)
            lab = load_label_csv(fi)  # (8,8)
            for r in range(8):
                for c in range(8):
                    self.samples.append((img_path, r, c, int(lab[r,c])))

        # transforms (augmentation은 적당히만)
        if train:
            self.tf = T.Compose([
                T.ToPILImage(),
                T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.05, hue=0.02),
                T.RandomAffine(degrees=3, translate=(0.02,0.02), scale=(0.98,1.02)),
                T.ToTensor(),
                T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
            ])
        else:
            self.tf = T.Compose([
                T.ToPILImage(),
                T.ToTensor(),
                T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
            ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, r, c, y = self.samples[idx]
        img = cv2.imread(img_path)
        img = cv2.resize(img, (640,480), interpolation=cv2.INTER_AREA)
        H, W = img.shape[:2]
        ch, cw = H//8, W//8
        cell = img[r*ch:(r+1)*ch, c*cw:(c+1)*cw]
        cell = cv2.resize(cell, (64,64), interpolation=cv2.INTER_AREA)
        cell = cv2.cvtColor(cell, cv2.COLOR_BGR2RGB)
        x = self.tf(cell)
        return x, y

# train/val split: 1~18 train, 19~20 val (원하면 바꿔도 됨)
train_frames = list(range(1, ))
val_frames   = [24, 25]

train_ds = ChessCellDataset(train_frames, train=True)
val_ds   = ChessCellDataset(val_frames, train=False)

train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)

# 모델: ResNet18
model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, 3)  # 0 empty, 1 white, 2 black
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)

def evaluate():
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for x, y in val_loader:
            x, y = x.to(device), y.to(device)
            pred = model(x).argmax(dim=1)
            correct += (pred == y).sum().item()
            total += y.numel()
    return correct / total

# 학습
best_acc = 0.0
best_path = "/content/best_cell_cls.pt"

for epoch in range(1, 13):  # 8 epoch 정도면 충분히 수렴할 확률 높음
    model.train()
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        logits = model(x)
        loss = criterion(logits, y)
        loss.backward()
        optimizer.step()

    acc = evaluate()
    print(f"epoch {epoch:02d} | val acc: {acc:.4f}")
    if acc > best_acc:
        best_acc = acc
        torch.save(model.state_dict(), best_path)

print("best val acc:", best_acc)

# best 모델 로드
model.load_state_dict(torch.load("/content/best_cell_cls.pt", map_location=device))
model.eval()

infer_tf = T.Compose([
    T.ToPILImage(),
    T.ToTensor(),
    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
])

def predict_frame_to_grid(frame_idx):
    img_path = find_frame_image(frame_idx)
    img = cv2.imread(img_path)
    img = cv2.resize(img, (640,480), interpolation=cv2.INTER_AREA)
    H, W = img.shape[:2]
    ch, cw = H//8, W//8

    grid = np.zeros((8,8), dtype=int)

    with torch.no_grad():
        batch = []
        coords = []
        for r in range(8):
            for c in range(8):
                cell = img[r*ch:(r+1)*ch, c*cw:(c+1)*cw]
                cell = cv2.resize(cell, (64,64), interpolation=cv2.INTER_AREA)
                cell = cv2.cvtColor(cell, cv2.COLOR_BGR2RGB)
                x = infer_tf(cell)
                batch.append(x)
                coords.append((r,c))

        batch = torch.stack(batch, dim=0).to(device)  # (64,3,64,64)
        preds = model(batch).argmax(dim=1).cpu().numpy()

        for (r,c), p in zip(coords, preds):
            grid[r,c] = int(p)

    return grid

# 21~25 생성
for fi in range(29, 31):
    pred_grid = predict_frame_to_grid(fi)
    out_csv = os.path.join(PRED_DIR, f"frame{fi:02d}.csv")
    save_label_csv(pred_grid, out_csv)
    print("saved:", out_csv)

#=====

# =========================
# 0) 설치/임포트/경로
# =========================
!pip -q install torch torchvision

import os, glob
import numpy as np
import pandas as pd
import cv2
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as T
import matplotlib.pyplot as plt

IMG_DIR   = "/content/drive/MyDrive/data/chess_photo"
LABEL_DIR = "/content/drive/MyDrive/data/chess_labels_csv"      # 정답 라벨(1~30)이 있어야 함
PRED_DIR  = "/content/drive/MyDrive/data/chess_labels_pred_csv" # 31~46 예측 저장
os.makedirs(PRED_DIR, exist_ok=True)

device = "cuda" if torch.cuda.is_available() else "cpu"
print("device:", device)

FILES = list("abcdefgh")
RANKS = [str(i) for i in range(1,9)]

# =========================
# 1) 유틸: 이미지/라벨 로드/저장
# =========================
def find_frame_image(frame_idx):
    key = f"frame{frame_idx:02d}"
    cand = sorted(glob.glob(os.path.join(IMG_DIR, key + ".*")))
    if len(cand) == 0:
        raise FileNotFoundError(f"No image found for {key} in {IMG_DIR}")
    return cand[0]

def load_label_csv(frame_idx):
    path = os.path.join(LABEL_DIR, f"frame{frame_idx:02d}.csv")
    df = pd.read_csv(path)
    arr = df.iloc[:, 1:].astype(int).values
    assert arr.shape == (8,8)
    return arr

def save_label_csv(arr_8x8, out_path):
    df = pd.DataFrame(arr_8x8, columns=RANKS)
    df.insert(0, "", FILES)
    df.to_csv(out_path, index=False)

def check_labels_exist(frames):
    missing = []
    for fi in frames:
        p = os.path.join(LABEL_DIR, f"frame{fi:02d}.csv")
        if not os.path.exists(p):
            missing.append(fi)
    return missing

# =========================
# 2) 데이터셋 (칸 단위 3-class)
# =========================
class ChessCellDataset(Dataset):
    def __init__(self, frame_indices, train=True):
        self.samples = []
        self.train = train

        for fi in frame_indices:
            img_path = find_frame_image(fi)
            lab = load_label_csv(fi)
            for r in range(8):      # a..h (위->아래)
                for c in range(8):  # 1..8 (왼->오)
                    self.samples.append((img_path, r, c, int(lab[r,c])))

        if train:
            self.tf = T.Compose([
                T.ToPILImage(),
                T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.05, hue=0.02),
                T.RandomAffine(degrees=3, translate=(0.02,0.02), scale=(0.98,1.02)),
                T.ToTensor(),
                T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
            ])
        else:
            self.tf = T.Compose([
                T.ToPILImage(),
                T.ToTensor(),
                T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
            ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, r, c, y = self.samples[idx]
        img = cv2.imread(img_path)
        img = cv2.resize(img, (640,480), interpolation=cv2.INTER_AREA)
        H, W = img.shape[:2]
        ch, cw = H//8, W//8
        cell = img[r*ch:(r+1)*ch, c*cw:(c+1)*cw]
        cell = cv2.resize(cell, (64,64), interpolation=cv2.INTER_AREA)
        cell = cv2.cvtColor(cell, cv2.COLOR_BGR2RGB)
        x = self.tf(cell)
        return x, y

# =========================
# 3) 학습 설정: 1~28 train, 29~30 val
# =========================
train_frames = list(range(1, 29))  # 1~28
val_frames   = [29, 30]            # 29~30

missing = check_labels_exist(list(range(1,31)))
if missing:
    raise RuntimeError(f"Missing label CSVs in LABEL_DIR for frames: {missing}\n"
                       f"Please ensure frame01~frame30.csv exist in {LABEL_DIR}")

train_ds = ChessCellDataset(train_frames, train=True)
val_ds   = ChessCellDataset(val_frames, train=False)

train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)

# =========================
# 4) 모델 (ResNet18)
# =========================
model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, 3)  # 0 empty, 1 white, 2 black
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)

def evaluate():
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for x, y in val_loader:
            x, y = x.to(device), y.to(device)
            pred = model(x).argmax(dim=1)
            correct += (pred == y).sum().item()
            total += y.numel()
    return correct / total

best_acc = 0.0
best_path = "/content/best_cell_cls_1to30.pt"

# =========================
# 5) 학습
# =========================
for epoch in range(1, 13):  # 12 epoch 추천
    model.train()
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        logits = model(x)
        loss = criterion(logits, y)
        loss.backward()
        optimizer.step()

    acc = evaluate()
    print(f"epoch {epoch:02d} | val acc: {acc:.4f}")
    if acc > best_acc:
        best_acc = acc
        torch.save(model.state_dict(), best_path)

print("best val acc:", best_acc)

# =========================
# 6) 추론: frame31~46 -> CSV 저장
# =========================
infer_tf = T.Compose([
    T.ToPILImage(),
    T.ToTensor(),
    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
])

def predict_frame_to_grid(frame_idx):
    img_path = find_frame_image(frame_idx)
    img = cv2.imread(img_path)
    img = cv2.resize(img, (640,480), interpolation=cv2.INTER_AREA)
    H, W = img.shape[:2]
    ch, cw = H//8, W//8

    cells = []
    coords = []
    for r in range(8):
        for c in range(8):
            cell = img[r*ch:(r+1)*ch, c*cw:(c+1)*cw]
            cell = cv2.resize(cell, (64,64), interpolation=cv2.INTER_AREA)
            cell = cv2.cvtColor(cell, cv2.COLOR_BGR2RGB)
            cells.append(infer_tf(cell))
            coords.append((r,c))

    batch = torch.stack(cells, dim=0).to(device)  # (64,3,64,64)

    model.eval()
    with torch.no_grad():
        preds = model(batch).argmax(dim=1).cpu().numpy()

    grid = np.zeros((8,8), dtype=int)
    for (r,c), p in zip(coords, preds):
        grid[r,c] = int(p)
    return grid

# best 모델 로드
model.load_state_dict(torch.load(best_path, map_location=device))
model.eval()

for fi in range(31, 47):
    grid = predict_frame_to_grid(fi)
    out_csv = os.path.join(PRED_DIR, f"frame{fi:02d}.csv")
    save_label_csv(grid, out_csv)
    print("saved:", out_csv)

print("Done. Predictions saved to:", PRED_DIR)

# =========================
# 7) (선택) 오버레이로 확인
# =========================
def overlay_pred(img_bgr, grid):
    img = cv2.resize(img_bgr, (640,480), interpolation=cv2.INTER_AREA)
    H, W = img.shape[:2]
    ch, cw = H//8, W//8
    vis = img.copy()

    for r in range(8):
        for c in range(8):
            v = int(grid[r,c])
            x0, y0 = c*cw, r*ch
            x1, y1 = (c+1)*cw, (r+1)*ch
            if v == 1:
                cv2.rectangle(vis, (x0,y0), (x1,y1), (255,255,255), 2)
                cv2.putText(vis, "W", (x0+5,y0+20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            elif v == 2:
                cv2.rectangle(vis, (x0,y0), (x1,y1), (0,0,0), 2)
                cv2.putText(vis, "B", (x0+5,y0+20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)
    return vis

# 예: 31~33만 오버레이 확인
for fi in range(31, 34):
    img_path = find_frame_image(fi)
    img = cv2.imread(img_path)
    grid = pd.read_csv(os.path.join(PRED_DIR, f"frame{fi:02d}.csv")).iloc[:,1:].astype(int).values
    vis = overlay_pred(img, grid)
    plt.figure(figsize=(7,5))
    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))
    plt.title(f"frame{fi:02d} prediction overlay")
    plt.axis("off")
    plt.show()

